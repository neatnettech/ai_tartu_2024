{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neatnettech/ai_tartu_2024/blob/main/hubmap_segmentation_practice_no_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image segmentation for histopathology"
      ],
      "metadata": {
        "id": "ZU-Uwsv_0NOX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the data from Kaggle competition [HuBMAP - Hacking the Kidney](https://www.kaggle.com/competitions/hubmap-kidney-segmentation)"
      ],
      "metadata": {
        "id": "PR6EDJjW0WCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "JsNAZMGc0MD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Kaggle API key as shown [here](https://docs.google.com/presentation/d/17OppxF05HE9ABr1cQZQ2RXdF8UaZvuyRoxXTAFrUVLw/edit?usp=sharing). Then upload it to Colab home folder."
      ],
      "metadata": {
        "id": "U-HxwR922lrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle/\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "CstDZj4g2gQS",
        "outputId": "24951eae-d884-40a6-9676-5b8eec5ca810",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle/’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Bicd-Q7Dz_tR",
        "outputId": "2fa3940b-6c64-44e4-98b9-0bda90c71019",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Dataset URL: https://www.kaggle.com/datasets/iafoss/hubmap-256x256\n",
            "License(s): unknown\n",
            "Downloading hubmap-256x256.zip to /content\n",
            "100% 1.23G/1.23G [01:08<00:00, 22.4MB/s]\n",
            "100% 1.23G/1.23G [01:08<00:00, 19.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d iafoss/hubmap-256x256"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!unzip -q hubmap-256x256.zip -d data"
      ],
      "metadata": {
        "id": "-1_K59ch3QIt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Taking a look at the data"
      ],
      "metadata": {
        "id": "7XhUQFT048eC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "FrbHddYs4-wv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = Path(\"data\")\n",
        "img_path = data_path / \"train\"\n",
        "mask_path = data_path / \"masks\"\n",
        "\n",
        "images = sorted(img_path.glob(\"*.png\"))\n",
        "masks = sorted(mask_path.glob(\"*.png\"))\n",
        "\n",
        "images[:5] + masks[:5]"
      ],
      "metadata": {
        "id": "mbLSVvg5477h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_images = 4\n",
        "img_size = 4\n",
        "fig, axes = plt.subplots(ncols=n_images, nrows=2, figsize=(img_size * n_images, img_size * 2))\n",
        "for ax, im, ms in zip(axes.T, images, masks):\n",
        "    image = plt.imread(im)\n",
        "    mask = plt.imread(ms)\n",
        "    ax[0].imshow(image)\n",
        "    ax[1].imshow(mask)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m4RUGO4t5u9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "kiN5eZZg3NXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch import Tensor as T\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "from torchvision.transforms import v2\n",
        "from torchvision import tv_tensors\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "gbZ1db-r7U0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HubmapDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        images: list[Path],\n",
        "        masks: list[Path],\n",
        "        transforms: list[v2.Transform],\n",
        "        ):\n",
        "\n",
        "        super().__init__()\n",
        "        self.images = images\n",
        "        self.masks = masks\n",
        "        self.transforms = v2.Compose(transforms)\n",
        "\n",
        "    def __getitem__(self, i: int) -> dict[str, T]:\n",
        "        # Read one image by an index\n",
        "\n",
        "        image = Image.open(self.images[i]).convert(\"RGB\")\n",
        "        mask = Image.open(self.masks[i])\n",
        "\n",
        "        image = tv_tensors.Image(image)\n",
        "        mask = tv_tensors.Mask(mask, dtype=torch.float32)\n",
        "\n",
        "        sample = {\n",
        "            \"image\": image,\n",
        "            \"mask\": mask,\n",
        "        }\n",
        "\n",
        "        sample = self.transforms(sample)\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)"
      ],
      "metadata": {
        "id": "yywPLpvt2y9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check PyTorch documentation and fill in the list of train transforms."
      ],
      "metadata": {
        "id": "X1Zs_z5-kxtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transforms_val = [\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "]\n",
        "\n",
        "transforms_train = [\n",
        "    # https://pytorch.org/vision/stable/transforms.html\n",
        "    ### BEGIN SOLUTION\n",
        "    ### END SOLUTION\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "]"
      ],
      "metadata": {
        "id": "2SUqbugZkJKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split images into train and validation set"
      ],
      "metadata": {
        "id": "3fjLun18L-B5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_train, images_val, masks_train, masks_val = train_test_split(images, masks, test_size=0.2, random_state=11)\n",
        "len(images_train), len(images_val)"
      ],
      "metadata": {
        "id": "v_xHDGFXABuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = HubmapDataset(images_train, masks_train, transforms_train)\n",
        "ds_val = HubmapDataset(images_val, masks_val, transforms_val)"
      ],
      "metadata": {
        "id": "FYgGbNCu9tN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def denormalize(tensor: T,\n",
        "                mean: tuple[float, float, float] = (0.485, 0.456, 0.406),\n",
        "                std: tuple[float, float, float] = (0.229, 0.224, 0.225)):\n",
        "    return (np.moveaxis(tensor.numpy(), 0, -1) * std + mean).clip(0, 255)"
      ],
      "metadata": {
        "id": "5efZ2qK2-ENC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run cells below multiple times, notice the difference?"
      ],
      "metadata": {
        "id": "t9xfzkeqAj0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = ds_train[4000]\n",
        "\n",
        "fig, ax = plt.subplots(ncols=2, figsize=(img_size * 2, img_size))\n",
        "ax[0].imshow(denormalize(sample[\"image\"]))\n",
        "ax[1].imshow(sample[\"mask\"][0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HNwkba3V9z_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = ds_val[1000]\n",
        "\n",
        "fig, ax = plt.subplots(ncols=2, figsize=(img_size * 2, img_size))\n",
        "ax[0].imshow(denormalize(sample[\"image\"]))\n",
        "ax[1].imshow(sample[\"mask\"][0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ImMOzamqA6PX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loader\n",
        "\n",
        "Handles multiprocess data loading and batching. Check the documentation for details: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
      ],
      "metadata": {
        "id": "Yxqi4NrjKO_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "num_workers = 0\n",
        "\n",
        "loader_train = DataLoader(ds_train,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=num_workers)\n",
        "\n",
        "loader_val = DataLoader(ds_val,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=False,\n",
        "                        num_workers=num_workers)\n",
        "\n",
        "len(loader_train), len(loader_val)"
      ],
      "metadata": {
        "id": "L3FpB0giKQZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segmentation model"
      ],
      "metadata": {
        "id": "SdlFzbdiBuWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q segmentation-models-pytorch"
      ],
      "metadata": {
        "id": "SMgfh90KBw-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "model = smp.Unet(\n",
        "    encoder_name=\"resnet18\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
        "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
        "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
        "    classes=1,                      # model output channels (number of classes in your dataset)\n",
        ")"
      ],
      "metadata": {
        "id": "FZdxhSDmBx-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function\n",
        "\n",
        "We will use a combination of cross-entropy and Dice:\n",
        "\n",
        "$$\\text{Dice} = \\frac{\\text{2 * TP}}{\\text{2 * TP} + \\text{FP} + \\text{FN}}$$"
      ],
      "metadata": {
        "id": "Og7HptNZFuf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "from typing import Any, Callable\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "y6SwLxuyGiR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice(\n",
        "    outputs: T,\n",
        "    targets: T,\n",
        "    eps: float = 1e-7,\n",
        "    threshold: float = None,\n",
        "    sigmoid: bool = True,\n",
        ") -> T:\n",
        "    if sigmoid:\n",
        "        outputs = nn.functional.sigmoid(outputs)\n",
        "\n",
        "    if threshold is not None:\n",
        "        outputs = (outputs > threshold).float()\n",
        "\n",
        "    intersection = torch.sum(outputs * targets)\n",
        "    union = torch.sum(outputs) + torch.sum(targets)\n",
        "    score = (2 * intersection + eps * (union == 0)) / (union + eps)\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "def dice_loss(outputs: T, targets: T, **kwargs) -> T:\n",
        "    return 1 - dice(outputs, targets, **kwargs)"
      ],
      "metadata": {
        "id": "Fw_5R6cFFxwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Loss(nn.Module):\n",
        "    def __init__(self, loss_fn: Callable, element_wise: bool = False, **kwargs: Any):\n",
        "        super().__init__()\n",
        "        self.element_wise = element_wise\n",
        "        self.loss_fn = partial(loss_fn, **kwargs)\n",
        "\n",
        "    def forward(self, logits: T, targets: T) -> T:\n",
        "        \"\"\"\n",
        "        Calculates loss between ``logits`` and ``target`` tensors.\n",
        "        :param logits: model logits (B, C, H, W)\n",
        "        :param targets: ground truth labels (B, C, H, W)\n",
        "        :return: computed loss\n",
        "        \"\"\"\n",
        "        assert logits.shape == targets.shape\n",
        "        # Iterate over batch dimension if element_wise\n",
        "        if not self.element_wise:\n",
        "            logits, targets = [logits], [targets]\n",
        "        loss = torch.stack([self.loss_fn(o, t) for o, t in zip(logits, targets)])\n",
        "        return loss.mean()\n",
        "\n",
        "\n",
        "class DiceLoss(Loss):\n",
        "    def __init__(\n",
        "        self,\n",
        "        eps: float = 1e-7,\n",
        "        threshold: float = None,\n",
        "        sigmoid: bool = True,\n",
        "        element_wise: bool = False,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Dice loss\n",
        "\n",
        "        :param eps: smoothing parameter, default 1e-7\n",
        "        :param threshold: threshold logits if necessary\n",
        "        :param activation: activation function\n",
        "        :param element_wise: calculate by element in the batch, then average\n",
        "        \"\"\"\n",
        "        super().__init__(\n",
        "            loss_fn=dice_loss,\n",
        "            element_wise=element_wise,\n",
        "            threshold=threshold,\n",
        "            sigmoid=sigmoid,\n",
        "            eps=eps,\n",
        "        )"
      ],
      "metadata": {
        "id": "sqs_GlV3GgmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop"
      ],
      "metadata": {
        "id": "2_GoN1jfCR2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your task is to complete missing parts in the code below as the comments describe. If you struggle, take a look at the official [PyTorch tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) or ask straight away!"
      ],
      "metadata": {
        "id": "pde4xXICCxPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "KNt5PLLvCV_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(self, model: nn.Module, device: str = \"cuda\"):\n",
        "        self.device = device\n",
        "        self.criterion = {\n",
        "            \"bce\": nn.BCEWithLogitsLoss(),\n",
        "            \"dice\": DiceLoss(),\n",
        "        }\n",
        "        self.model = model\n",
        "        # TODO: you can try to parametrize optimizer later in your experiments\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters())\n",
        "        self.scheduler = None\n",
        "\n",
        "    def train(self,\n",
        "              epochs: int,\n",
        "              train_loader: DataLoader,\n",
        "              test_loader: DataLoader) -> tuple[list[float], list[float]]:\n",
        "        \"\"\"\n",
        "        Train loop\n",
        "\n",
        "        params:\n",
        "            train_loader: DataLoader, training loader\n",
        "            test_loader: DataLoader, test loader\n",
        "        returns: None\n",
        "        \"\"\"\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        # Logging\n",
        "        train_loss = []\n",
        "        test_acc = []\n",
        "\n",
        "        # Set up scheduler\n",
        "        # TODO: you can try to parametrize scheduler later in your experiments\n",
        "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "            self.optimizer, T_max=epochs * len(train_loader), eta_min=1e-7)\n",
        "\n",
        "\n",
        "        for i in range(epochs):\n",
        "            try:\n",
        "                loss = self.train_loop(train_loader, i)\n",
        "                acc = self.test_loop(test_loader)\n",
        "                train_loss.append(loss)\n",
        "                test_acc.append(acc)\n",
        "\n",
        "                # Save model checkpoint, use tutorial for the reference:\n",
        "                # https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
        "                ### BEGIN SOLUTION\n",
        "                ### END SOLUTION\n",
        "            except KeyboardInterrupt:\n",
        "                # so you can interrupt the kernel and stop the training\n",
        "                print(f\"Training interrupted at epoch {i}\")\n",
        "                break\n",
        "        return train_loss, test_acc\n",
        "\n",
        "\n",
        "    def train_loop(self, loader: DataLoader, epoch: int = 0) -> float:\n",
        "        \"\"\"\n",
        "        Train loop\n",
        "\n",
        "        params:\n",
        "            loader: DataLoader, training loader\n",
        "            epoch: int, epoch id for logging\n",
        "        returns: float, average loss\n",
        "        \"\"\"\n",
        "        # Set training mode for `self.model`\n",
        "        # https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch\n",
        "        ### BEGIN SOLUTION\n",
        "        ### END SOLUTION\n",
        "\n",
        "        # Set up logging\n",
        "        iterator = tqdm(loader, desc=f\"ep.{epoch:04d}\", position=0)\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, batch in enumerate(iterator):\n",
        "            inputs, labels = batch[\"image\"], batch[\"mask\"]\n",
        "            # Move both inputs and labels to `self.device`\n",
        "            # https://stackoverflow.com/questions/63061779/pytorch-when-do-i-need-to-use-todevice-on-a-model-or-tensor\n",
        "            ### BEGIN SOLUTION\n",
        "            ### END SOLUTION\n",
        "\n",
        "            # Zero the parameter gradients using the respective method of `self.optimizer`\n",
        "            # https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html\n",
        "            ### BEGIN SOLUTION\n",
        "            ### END SOLUTION\n",
        "\n",
        "            # Do forward pass of `self.model`\n",
        "            # https://stackoverflow.com/questions/55338756/why-there-are-different-output-between-model-forwardinput-and-modelinput\n",
        "            outputs = ...\n",
        "            ### BEGIN SOLUTION\n",
        "            ### END SOLUTION\n",
        "\n",
        "            # Calculate the loss using the outputs of your model\n",
        "            # Hint: criterion is a dict, take functions by keys.\n",
        "            loss_bce = ...\n",
        "            loss_dice = ...\n",
        "            ### BEGIN SOLUTION\n",
        "            ### END SOLUTION\n",
        "            # TODO: experiment with loss weights\n",
        "            loss = loss_bce + loss_dice\n",
        "\n",
        "            # Do backward pass using the respective method of `loss`\n",
        "            # https://discuss.pytorch.org/t/what-does-the-backward-function-do/9944\n",
        "            ### BEGIN SOLUTION\n",
        "            ### END SOLUTION\n",
        "\n",
        "            # Do an optimization step using the respective method of `self.optimizer`\n",
        "            # https://stackoverflow.com/questions/53975717/pytorch-connection-between-loss-backward-and-optimizer-step\n",
        "            ### BEGIN SOLUTION\n",
        "            ### END SOLUTION\n",
        "\n",
        "            # Do a scheduler step using the respective method of `self.scheduler`\n",
        "            if self.scheduler is not None:\n",
        "                ### BEGIN SOLUTION\n",
        "                ### END SOLUTION\n",
        "                pass\n",
        "\n",
        "\n",
        "            # Show training statistics\n",
        "            # NB! Always use loss.item() and not just loss when storing the value!\n",
        "            # Otherwise you will quickly run out of memory\n",
        "            running_loss += loss.item()\n",
        "            iterator.set_postfix({\"loss\": running_loss / (i + 1),\n",
        "                                 \"lr\": f\"{self.scheduler.get_last_lr()[0]: .4e}\"})\n",
        "\n",
        "        return running_loss / len(iterator)\n",
        "\n",
        "    def test_loop(self, loader: DataLoader) -> float:\n",
        "        \"\"\"\n",
        "        Test loop\n",
        "\n",
        "        params:\n",
        "            loader: DataLoader, test loader\n",
        "        returns: float, accuracy\n",
        "        \"\"\"\n",
        "        # Set evaluation mode for `self.model`\n",
        "        # https://stackoverflow.com/questions/60018578/what-does-model-eval-do-in-pytorch\n",
        "        ### BEGIN SOLUTION\n",
        "        ### END SOLUTION\n",
        "\n",
        "        # Set up logging\n",
        "        iterator = tqdm(loader, position=0)\n",
        "        running_metric = 0\n",
        "\n",
        "        # We do not need gradients in test phase, so we use `no_grad` scope\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(iterator):\n",
        "                inputs, labels = batch[\"image\"], batch[\"mask\"]\n",
        "                # Move both inputs and labels to `self.device`\n",
        "                ### BEGIN SOLUTION\n",
        "                ### END SOLUTION\n",
        "\n",
        "                # Do forward pass of `self.model`\n",
        "                ### BEGIN SOLUTION\n",
        "                ### END SOLUTION\n",
        "\n",
        "                # The class with the highest energy is what we choose as prediction\n",
        "                metric = dice(outputs, labels)\n",
        "                running_metric += metric.item()\n",
        "\n",
        "                # Show current results (accuracy)\n",
        "                iterator.set_postfix({\"dice\": running_metric / (i + 1)})\n",
        "\n",
        "        return running_metric / len(iterator)"
      ],
      "metadata": {
        "id": "N0o9krY3B9JV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using\", device)\n",
        "\n",
        "trainer = Trainer(model, device=device)"
      ],
      "metadata": {
        "id": "eUpiaMO0KDGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_baseline, test_dice_baseline = trainer.train(2, loader_train, loader_val)"
      ],
      "metadata": {
        "id": "VsIT3qofKG52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can download the weights from Files menu on the left."
      ],
      "metadata": {
        "id": "qPG7en6gMnX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deployment\n",
        "\n",
        "1. [Sign in](https://share.streamlit.io/signup) to Streamlit Community Cloud\n",
        "2. Follow [instructions](https://docs.streamlit.io/streamlit-community-cloud/get-started/quickstart) to setup Github Workspaces"
      ],
      "metadata": {
        "id": "J2WQ_tz0Ozvt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your code is running in a container: you need to add required packages and rebuild it\n",
        "```\n",
        "torch\n",
        "torchvision\n",
        "segmentation-models-pytorch\n",
        "```\n"
      ],
      "metadata": {
        "id": "w5KCTDVFVhAZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create `Segmentation_Demo.py` file in `pages`:\n",
        "\n",
        "```\n",
        "import streamlit as st\n",
        "from streamlit.hello.utils import show_code\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision.transforms import v2\n",
        "from torchvision import tv_tensors\n",
        "from PIL import Image\n",
        "\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "\n",
        "def segmentation_demo():\n",
        "    model_weights = st.file_uploader(\"Choose a model file\")\n",
        "    image = st.file_uploader(\"Choose an image\")\n",
        "\n",
        "    if image is not None:\n",
        "        image = Image.open(image).convert(\"RGB\")\n",
        "        st.image(image, \"Uploaded image\")\n",
        "\n",
        "    if model_weights is not None:\n",
        "        # Define model as above since you saved only the weights\n",
        "        model = ...\n",
        "        ### BEGIN SOLUTION\n",
        "        \n",
        "        ### END SOLUTION\n",
        "\n",
        "        # Load model (be careful with `map_location`, read documentation above)\n",
        "        ### BEGIN SOLUTION\n",
        "        \n",
        "        ### END SOLUTION\n",
        "\n",
        "        # Switch to eval mode (as in test loop)\n",
        "        ### BEGIN SOLUTION\n",
        "        \n",
        "        ### END SOLUTION\n",
        "\n",
        "        # Use the same transforms as above\n",
        "        transforms = ...\n",
        "        ### BEGIN SOLUTION\n",
        "        \n",
        "        ### END SOLUTION\n",
        "\n",
        "        if image is not None:\n",
        "            # Apply transforms (don't forget to wrap image as tv_tensors.Image)\n",
        "            tensor = ...\n",
        "\n",
        "            ### BEGIN SOLUTION\n",
        "            \n",
        "            ### END SOLUTION\n",
        "\n",
        "            # Add batch dimension\n",
        "            tensor = tensor[None, ...]\n",
        "\n",
        "            # Do the forward pass (don't forget `torch.no_grad()`!)\n",
        "            ### BEGIN SOLUTION\n",
        "            \n",
        "            ### END SOLUTION\n",
        "\n",
        "            # Show image\n",
        "            st.image(mask[0, 0], \"Predicted mask\")\n",
        "\n",
        "# Setup page\n",
        "st.set_page_config(page_title=\"Segmentation Demo\", page_icon=\"🔬\")\n",
        "st.markdown(\"# Segmentation Demo\")\n",
        "st.sidebar.header(\"Segmentation Demo\")\n",
        "\n",
        "# Run page\n",
        "segmentation_demo()\n",
        "\n",
        "show_code(segmentation_demo)\n",
        "```"
      ],
      "metadata": {
        "id": "yDG_TMuEbvGN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IXRlDChwKt13"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}